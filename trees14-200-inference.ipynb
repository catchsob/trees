{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d08701aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "YOUR_HDF5_MODEL = 'trees14-moblienetv2-200-acc0.714.h5'\n",
    "\n",
    "model = keras.models.load_model(YOUR_HDF5_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40683ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT = ['榕樹', '白千層', '楓香', '台灣欒樹', '小葉欖仁', '大葉欖仁', '茄冬',\n",
    "       '黑板樹', '大王椰子', '鳳凰木', '阿勃勒', '水黃皮', '樟樹', '苦楝']\n",
    "\n",
    "def preprocess_image(f, res=200):\n",
    "    img = Image.open(f)\n",
    "    img = img.resize((res, res))\n",
    "    data = np.array(img.getdata())\n",
    "    img = data.reshape(1, *img.size, 3)\n",
    "    img = img.astype('float32')\n",
    "    img /= 255.\n",
    "            \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f993b904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "小葉欖仁 for 0.112 secs\n"
     ]
    }
   ],
   "source": [
    "now = time()\n",
    "f = 'tm.jpg'\n",
    "img = preprocess_image(f)\n",
    "print(f'{CAT[np.argmax(model.predict(img))]} for {time()-now:.3f} secs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7d49bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tm.jpg: 小葉欖仁\n",
      "bj.jpg: 榕樹\n",
      "rr.jpg: 大王椰子\n",
      "for 0.276 secs\n"
     ]
    }
   ],
   "source": [
    "now = time()\n",
    "fs = ['tm.jpg', 'bj.jpg', 'rr.jpg']\n",
    "for f in fs:\n",
    "    img = preprocess_image(f)\n",
    "    print(f'{f}: {CAT[np.argmax(model.predict(img))]}')\n",
    "print(f'for {time()-now:.3f} secs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e7099f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trees14-moblienetv2-200-acc0.714\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('trees14-moblienetv2-200-acc0.714')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41bf2e95",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "TensorRT integration is not available on Windows.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22508/1566867288.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorrt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensorrt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConversionParams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'FP16'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mconverter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensorrt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConverter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_saved_model_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"trees14-moblienetv2-200-acc0.714\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconversion_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf243\\lib\\site-packages\\tensorflow\\python\\compiler\\tensorrt\\trt_convert_windows.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, rewriter_config_template, max_workspace_size_bytes, precision_mode, minimum_segment_size, is_dynamic_op, maximum_cached_engines, use_calibration, max_batch_size)\u001b[0m\n\u001b[0;32m     91\u001b[0m               max_batch_size=1):\n\u001b[0;32m     92\u001b[0m     raise NotImplementedError(\n\u001b[1;32m---> 93\u001b[1;33m         \"TensorRT integration is not available on Windows.\")\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: TensorRT integration is not available on Windows."
     ]
    }
   ],
   "source": [
    "from tensorflow.experimental import tensorrt\n",
    "\n",
    "params = tensorrt.ConversionParams(precision_mode='FP16')\n",
    "converter = tensorrt.Converter(input_saved_model_dir=\"trees14-moblienetv2-200-acc0.714\", conversion_params=params)\n",
    "converter.convert()\n",
    "converter.save(output_saved_model_dir='qq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e6cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.experimental.tensorrt.Converter(\n",
    "    input_saved_model_dir='trees14-moblienetv2-200-acc0.714', input_saved_model_tags=None,\n",
    "    input_saved_model_signature_key=None, use_dynamic_shape=None,\n",
    "    dynamic_shape_profile_strategy=None, conversion_params=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf71edad",
   "metadata": {},
   "source": [
    "##  ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ec20028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "CAT = ['榕樹', '白千層', '楓香', '台灣欒樹', '小葉欖仁', '大葉欖仁', '茄冬',\n",
    "       '黑板樹', '大王椰子', '鳳凰木', '阿勃勒', '水黃皮', '樟樹', '苦楝']\n",
    "\n",
    "def preprocess_image(f, res=200):\n",
    "    img = Image.open(f)\n",
    "    img = img.resize((res, res))\n",
    "    data = np.array(img.getdata())\n",
    "    img = data.reshape(1, *img.size, 3)\n",
    "    img = img.astype('float32')\n",
    "    img /= 255.\n",
    "            \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffb6ef1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "小葉欖仁\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "img = preprocess_image('tm.jpg')\n",
    "onnx_model = onnx.load(\"trees14-moblienetv2-200-acc0.714.onnx\")  # load onnx model\n",
    "r = prepare(onnx_model).run(img)  # run the loaded model\n",
    "print(CAT[np.argmax(r)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "988e798a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大王椰子\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    " \n",
    "img = preprocess_image('rr.jpg')\n",
    "session = onnxruntime.InferenceSession('trees14-moblienetv2-200-acc0.714.onnx')\n",
    "r = session.run(None, {\"input_8:0\": img})\n",
    "print(CAT[np.argmax(r)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf104370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'trees14-moblienetv2-200-acc0.714.onnx' at http://localhost:8080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('localhost', 8080)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import netron\n",
    "netron.start('trees14-moblienetv2-200-acc0.714.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb834628",
   "metadata": {},
   "source": [
    "## Channel First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b861d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "YOUR_HDF5_MODEL = 'trees14-moblienetv3S400CF-ep156-loss1.914-acc0.580.h5'\n",
    "\n",
    "model = keras.models.load_model(YOUR_HDF5_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19cdde2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT = ['榕樹', '白千層', '楓香', '台灣欒樹', '小葉欖仁', '大葉欖仁', '茄冬',\n",
    "       '黑板樹', '大王椰子', '鳳凰木', '阿勃勒', '水黃皮', '樟樹', '苦楝']\n",
    "\n",
    "def preprocess_image(f, res=200):\n",
    "    img = Image.open(f)\n",
    "    img = img.resize((res, res))\n",
    "    data = np.array(img.getdata())\n",
    "    img = data.reshape(1, *img.size, 3)\n",
    "    img = img.astype('float32')\n",
    "    img = np.moveaxis(img, 3, 1)\n",
    "            \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66d57eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tm.jpg: 樟樹\n",
      "bj.jpg: 茄冬\n",
      "rr.jpg: 小葉欖仁\n",
      "for 0.809 secs\n"
     ]
    }
   ],
   "source": [
    "now = time()\n",
    "fs = ['tm.jpg', 'bj.jpg', 'rr.jpg']\n",
    "for f in fs:\n",
    "    img = preprocess_image(f, 400)\n",
    "    print(f'{f}: {CAT[np.argmax(model.predict(img))]}')\n",
    "print(f'for {time()-now:.3f} secs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53710c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tm.jpg: 樟樹\n",
      "bj.jpg: 茄冬\n",
      "rr.jpg: 小葉欖仁\n",
      "for 0.719 secs\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "now = time()\n",
    "fs = ['tm.jpg', 'bj.jpg', 'rr.jpg']\n",
    "for f in fs:\n",
    "    img = preprocess_image(f, 400)\n",
    "    print(f'{f}: {CAT[np.argmax(model.predict(img))]}')\n",
    "print(f'for {time()-now:.3f} secs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20f516dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'onnxmltools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-41f21be38fc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0monnxmltools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mkeras_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trees14-moblienetv3S400CF-ep156-loss1.914-acc0.580.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'onnxmltools'"
     ]
    }
   ],
   "source": [
    "# import onnx\n",
    "# import onnxmltools\n",
    "\n",
    "# keras_model = keras.models.load_model('trees14-moblienetv3S400CF-ep156-loss1.914-acc0.580.h5')\n",
    "# onnx_path = 'some.onnx'\n",
    "# onnx_model = onnxmltools.convert_keras(keras_model)\n",
    "# onnx_model.graph.input[0].type.tensor_type.shape.dim[0].dim_value = 1\n",
    "# onnx_model.graph.output[0].type.tensor_type.shape.dim[0].dim_value = 1\n",
    "# onnx.checker.check_model(onnx_model)\n",
    "# onnx.save(onnx_model, onnx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf117105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
